

# 븐류 알고리즘
# - 분류는 학습 데이터로 주어진 데이터의 피처와 레이블값(결정 값, 클래스 값)을 머신러닝 알고리즘으로 학습해 모델을 생성하고,
#   이렇게 생성된 모델에 새로운 데이터 값이 주어졌을 때 미지의 레이블 값을 예측한다

# - 베이즈(Bayes)통계와 생성 모델에 기반한 나이브 베이지
# - 독립변수와 종속변수의 선형 관계성에 기반한 로지스틱 회귀 -> Logistict Regression
# - 데이터 균일도에 따른 규칙 기반의 결정 트리 -> Decision Tree
# - 개별 클래스 간의 최대 분류 마진을 효과적으로 찾아주는 서포트 벡터 머신 -> Suppot Vector Machine
# - 근접 거리를 기준으로 하는 최소 근접 알고리즘 -> Nearest Neighbor
# - 심층 연결 기반의 신경망 -> Neural Network
# - 서로 다른(또는 같은) 머신러닝 알고리즘을 결합한 앙상블 -> Ensemble

# 결정 트리와 상상블
# - 결정 트리는 매우 쉽고 유연하게 적용될 수 있는 알고리즘이다. 또한 데이터의 스케일링이나 정규화 등의 사전 가공의 영향이 매우 적다
#   하지만 예측 성능을 향상시키기 위해 복자한 규칙 구조를 가져야하며, 이로 인한 과접합(overfitting)이 발생해 반대로 예측 성능이 저하
#   될 수도 있다는 단점이 있다
# - 하지만 이러한 단점이 앙상블 기법에서는 오히려 장점으로 작용한다. 앙상블은 매우 많은 여러 개의 약한 학습기 (예측 성능이 상대적으로 떨어지는
#   학습 알고리즘)을 결합해 확률적 보완과 오류가 발생한 부분이 대한 가중치를 계속 업데이트하면서 예측 성능을 향상 시키니느데, 결정 트리가 좋은
#   약한 학습기가 되기 때문이다 (GBM, XGBoost, LightGBM 등)

# 결정 트리
# - 결정 트리 알고리즘은 데이터에 있는 규칙을 학습을 통해 자동으로 찾아내 트리 기반의 분류 규칙을 만든다 (if - else 구조)
# - 따라서 데이터의 어떤 기준을 바탕으로 규칙을 만들어야 가장 효율적인 분류가 될 것인가가 알고리즘의 성능을 크기 좌우한다

# 정보 균일도 측정 방법
# - 정보 이득 (Information Gain)
#   - 정보 이득은 엔트로피라는 개념을 기반으로 한다. 엔트로피는 주어진 데이터 집합의 혼잡도를 의미하는데, 서로 다른 값이 섞여 있으면
#     엔트로피가 높고 같은 값이 섞여 있으면 엔트로피가 낮다. 정보 이득 지수는 1에서 엔트로피 지수를 뺀 값이다. 즉 1 - 엔트로피 지수
#     결정 트리는 이 정보 이득 지수로 분할 기준을 정한다. 즉, 정보 이득이 높은 속성을 기준으로 분할한다
# - 지니 계수
#   - 지니 계수는 원래 경제학에서 불평등 지수를 나타낼 때 사용하는 계수이다. 0 -> 가장 평등 1 -> 가장 불평등
#     머신러닝에 적용될 때는 지니 계수가 낮을 수록 데이터 균일도가 높은 것으로 해석되어 계수가 낮은 속성을 기준으로 분할한다

# 결정 트리의 규칙 노드 생성 프로세스
# - 데이터를 분할하는데 가장 좋은 속성과 분할 기준을 찾음 -> 정보이득, 지니계수 이용
# - 해당 속성과 분할 기준으로 데이터 분할하여 규칙 브랜치 노드 생성
# - 반복

# 결정 트리 주요 하이퍼 파라미터
# - 트리가 무한히 넓어지는 경향(오버 핏)이 있기 때문에 트리의 크기를 조절 하는 파라미터가 많다
# - max_depth
#   - 디폴트 는 none으로 none일 경우 완벽하게 클래스 결정 값이 될 때까지 깊이를 계쏙 키우며 분할하거나 노드가 가지는 데이터 개수가
#     min_samples_split보다 작아질 때까지 계속 깊이를 증가 시킴
#   - 깊이가 깊어지면 min_sampels_split설정대로 최대 분할하여 과적합할 수 있으므로 적절한 값으로 제어 필
# - max features요
#   - 최적의 분할을 위해 고려할 최대 피처개수, 디폴트는 none으로 데이터 세트의 모든 피처를 사용해 분할 수행
#   - 인트형으로 지정하면 대상 피처의 개수, float형으로 지정하면 전체 피처 중 대상 피처의 퍼센트로 적용
#   - sqrt는 전체 피처중 sqrt(전체 피처개수), 즉 루트 피처개수 만큼 적용
#   - auto로 설정 하면 루트와 동일
#   - log는 log2(피처 개수) 로 선
# - min_samples_split정
#   - 노드를 분할하기 위한 최소한의 샘플 데이터 수로 과적합을 제어하는데 사용됨
#   - 디폴트는 2이고 작게 설정할수록 분할되는 노드가 많아져서 과적합이 된다
#   - 과적합을 제어. 1로 설정할 경우 분할되는 노드가 많아져서 과적합 증가
# - min_samples_leaf
#   - 말단 노드가 되기 위한 최소한의 샘풀 데이터 수
#   - min_samples_split과 유사하게 과적합 제어 용도, 그러나 비대칭적 데이터의 경우 특정 클래스의 데이터가 극도로 작을수 있으므로
#     이경우에는 작게 설정할 필요가 있다
# - max_leaf_nodes
#   - 말단 노드의 최대 개수
